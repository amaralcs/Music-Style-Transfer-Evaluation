{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChordGAN\n",
    "\n",
    "This notebook aims to replicate the work done to create `chordGAN` but using TF 2 instead, since the other version is old and deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.6.0\n",
      "Keras version: 2.6.0\n",
      "Numpy version: 1.21.2\n"
     ]
    }
   ],
   "source": [
    "import pretty_midi\n",
    "import reverse_pianoroll\n",
    "import convert\n",
    "import librosa\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input, Concatenate\n",
    "from keras.initializers import GlorotNormal\n",
    "from keras.activations import sigmoid\n",
    "from keras.losses import Loss\n",
    "\n",
    "%load_ext lab_black\n",
    "\n",
    "# python script, in github repo\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)\n",
    "print(\"Numpy version:\", np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following to avoid GPU errors (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "# for device in physical_devices:\n",
    "#     tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add songs to data\n",
    "def get_songs(path):\n",
    "    files = glob.glob(\"{}/*.mid*\".format(path))\n",
    "    songs = []\n",
    "    for f in files:\n",
    "        try:\n",
    "            data = pretty_midi.PrettyMIDI(f)\n",
    "            song = data.get_piano_roll(fs=16)\n",
    "            song = convert.forward(song)\n",
    "            # song = np.transpose(song) - if your code matrices aren't working, try uncommenting this. the convert.py file might not be updated\n",
    "            songs.append(song)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    return songs\n",
    "\n",
    "# custom function to extract chroma features from song\n",
    "def get_chromas(songs):\n",
    "    chromas = []\n",
    "    for song in songs:\n",
    "        chroma = np.zeros(shape=(np.shape(song)[0], 12))\n",
    "        for i in np.arange(np.shape(song)[0]):\n",
    "            for j in np.arange(78):\n",
    "                if song[i][j] > 0:\n",
    "                    chroma[i][np.mod(j, 12)] += 1\n",
    "        # print(np.shape(chroma))\n",
    "        chromas.append(chroma)\n",
    "\n",
    "    return chromas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gamin\\anaconda3\\envs\\chordgan\\lib\\site-packages\\pretty_midi\\pretty_midi.py:97: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 songs processed\n",
      "10 songs processed\n"
     ]
    }
   ],
   "source": [
    "songs = get_songs(\"../data/chordGan/Pop/Pop_Music_Midi\")[:10]\n",
    "chromas = get_chromas(songs)\n",
    "print(\"{} songs processed\".format(len(songs)))\n",
    "print(\"{} songs processed\".format(len(chromas)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup GAN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "The discriminator has both the song timeseries and the chromagram as inputs, hence the two-dimensional inputs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xavier_init = GlorotNormal(shape=[X_dim + Z_dim, 512])# AKA xavier init\n",
    "\n",
    "\n",
    "def xavier_init(size, dtype=None):\n",
    "    input_dim = size[0]\n",
    "    xavier_stddev = 1.0 / tf.sqrt(input_dim / 2)\n",
    "    return tf.random.normal(shape=size, stddev=xavier_stddev)\n",
    "\n",
    "\n",
    "def build_generator(Z_dim, n_units=128):\n",
    "    inputs = Input(shape=[None, Z_dim])\n",
    "    z = Dense(n_units, kernel_initializer=xavier_init, activation=\"relu\")(inputs)\n",
    "    output = Dense(X_dim, kernel_initializer=xavier_init, activation=\"sigmoid\")(z)\n",
    "\n",
    "    return Model(inputs=[inputs], outputs=[output], name=\"generator\")\n",
    "\n",
    "\n",
    "def build_discriminator(X_dim, Z_dim, n_units=512):\n",
    "    data_inputs = Input(shape=[None, X_dim], name=\"data_input\")\n",
    "    chroma_inputs = Input(shape=[None, Z_dim], name=\"chroma_input\")\n",
    "\n",
    "    x = Concatenate(axis=2)([data_inputs, chroma_inputs])\n",
    "    x = Dense(n_units, kernel_initializer=xavier_init, activation=\"relu\")(x)\n",
    "    logits = Dense(1, kernel_initializer=xavier_init)(x)\n",
    "    probas = sigmoid(logits)\n",
    "\n",
    "    return Model(inputs=[data_inputs, chroma_inputs], outputs=[logits, probas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(\n",
    "    D_fake_logits,\n",
    "    fake_samples,\n",
    "    z,\n",
    "    lambda_=100,\n",
    "    gen_loss=keras.losses.MeanSquaredError(),\n",
    "):\n",
    "    \"\"\"\n",
    "    Note: While the paper describes L1 loss (which is MAE) the code uses MSE.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    D_fake_logits:\n",
    "        The logits output by the discriminator given the fake sample.\n",
    "    fake_samples :\n",
    "        The sample data created by the generator.\n",
    "    z:\n",
    "        The real chromagram data.\n",
    "    lambda_ : float, Optional\n",
    "        Normalization factor\n",
    "    gen_loss :\n",
    "        The type of loss to use for the generated fake samples.\n",
    "    \"\"\"\n",
    "    binary_cross_entropy = keras.losses.BinaryCrossEntropy(from_logits=True)\n",
    "\n",
    "    # Probability the generator fooled the discriminator (i.e. all predictions on fake samples were labelled 1)\n",
    "    G_fooling = tf.reduce_mean(\n",
    "        binary_cross_entropy(tf.ones_like(D_fake_logits), D_fake_logits)\n",
    "    )\n",
    "    G_loss = tf.reduce_mean(gen_loss(z, fake_samples))\n",
    "    return G_fooling + lambda_ * G_loss\n",
    "\n",
    "\n",
    "def discriminator_loss(discriminator, true_samples, fake_samples):\n",
    "    binary_cross_entropy = keras.losses.BinaryCrossEntropy(from_logits=True)\n",
    "\n",
    "    D_true_logits, _ = discriminator(true_samples)\n",
    "    D_fake_logits, _ = discriminator(fake_samples)\n",
    "\n",
    "    # Discriminator should identify the true samples as 1s\n",
    "    D_true_loss = tf.reduce_mean(\n",
    "        binary_cross_entropy(np.ones_like(D_true_logits), true_logits)\n",
    "    )\n",
    "    # And the fake samples as 0s\n",
    "    D_fake_loss = tf.reduce_mean(\n",
    "        binary_cross_entropy(np.zeros_like(D_fake_logits), fake_logits)\n",
    "    )\n",
    "    return D_loss_real + D_loss_fake, D_fake_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_dim = 624\n",
      "Z_dim = 48\n"
     ]
    }
   ],
   "source": [
    "low_note, high_note = 0, 78  # The index of lowest/highest note on the piano roll\n",
    "note_range = high_note - low_note\n",
    "\n",
    "n_timesteps = 4  # This is the number of timesteps that we will create at a time\n",
    "X_dim = 2 * note_range * n_timesteps  # This is the size of the visible layer.\n",
    "Z_dim = 12 * n_timesteps\n",
    "n_hidden = 50  # This is the size of the hidden layer\n",
    "\n",
    "print(f\"X_dim = {X_dim}\")\n",
    "print(f\"Z_dim = {Z_dim}\")\n",
    "\n",
    "discriminator = build_discriminator(X_dim, Z_dim)\n",
    "generator = build_generator(Z_dim)\n",
    "\n",
    "D_optimizer = keras.optimizers.Adam()\n",
    "G_optimizer = keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.floor(songs[0].shape[0] / n_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs[0].shape[0] // n_timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "batch_size = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}/{num_epochs}\", flush=True)\n",
    "    for song, chroma in zip(songs, chromas):\n",
    "        # Reshape song from song_timesteps x 2*note_range\n",
    "        # to n_timesteps x 2*note_range\n",
    "        # print(\"initial song shape\", song.shape)\n",
    "        song_timesteps = song.shape[0] // n_timesteps\n",
    "        song = song[: song_timesteps * n_timesteps]  # discard any extra timesteps\n",
    "        song = song.reshape([song_timesteps, song.shape[1] * n_timesteps])\n",
    "        # print(\"  final song shape\", song.shape)\n",
    "\n",
    "        # Similar process for the chroma\n",
    "        # print(\"initial chroma shape\", chroma.shape)\n",
    "        chroma = chroma[: song_timesteps * n_timesteps]\n",
    "        chroma = chroma.reshape([song_timesteps, chroma.shape[1] * n_timesteps])\n",
    "        # print(\"  final chroma shape\", chroma.shape)\n",
    "\n",
    "        # TODO: write training loop"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c451df2ee4a022de8b5d34d0f5e786a0cd89accac380895e70e2986b6f15379b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('chordgan': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

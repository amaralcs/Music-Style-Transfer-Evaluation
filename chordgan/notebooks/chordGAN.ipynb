{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXqiXvjmGkVv"
      },
      "source": [
        "# 1. Imports and Loading Data\n",
        "Before running, please upload the following to the \"Files\" tab:\n",
        "- reverse_pianoroll.py\n",
        "- convert.py\n",
        "- Pop_Music_Midi.zip\n",
        "\n",
        "All can be found on GitHub (github.com/conanlu/composeGAN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zR2xjd5_8g2N"
      },
      "outputs": [],
      "source": [
        "# !pip install pretty_midi\n",
        "# !pip install librosa\n",
        "import pretty_midi\n",
        "import reverse_pianoroll\n",
        "import convert\n",
        "import librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LNiQvohD8g25"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SWV1ONBqEj1t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF version: 2.6.0\n",
            "Numpy version: 1.21.2\n"
          ]
        }
      ],
      "source": [
        "#all necessary imports: use pip install [library name] to add to environment\n",
        "#this notebook was run in 2019 with tensorflow version 1.15. some functions may or may not work with tensorflow > 2.0\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import os\n",
        "from os import listdir\n",
        "import glob\n",
        "\n",
        "#python script, in github repo\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Numpy version:\", np.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "\n",
        "for device in physical_devices:\n",
        "    tf.config.experimental.set_memory_growth(device, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "t0MVvlIeEj1v"
      },
      "outputs": [],
      "source": [
        "#add songs to data\n",
        "def get_songs(path):\n",
        "    files = glob.glob('{}/*.mid*'.format(path))\n",
        "    songs = []\n",
        "    for f in files:\n",
        "        try:\n",
        "            data = pretty_midi.PrettyMIDI(f)\n",
        "            song = data.get_piano_roll(fs=16)\n",
        "            song = convert.forward(song)\n",
        "            #song = np.transpose(song) - if your code matrices aren't working, try uncommenting this. the convert.py file might not be updated\n",
        "            songs.append(song)\n",
        "        except Exception as e:\n",
        "            raise e           \n",
        "    return songs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4MYRJza_Ej1v"
      },
      "outputs": [],
      "source": [
        "#custom function to extract chroma features from song\n",
        "def get_chromas(songs):\n",
        "    chromas = []\n",
        "    for song in songs: \n",
        "        chroma = np.zeros(shape=(np.shape(song)[0], 12))\n",
        "        for i in np.arange(np.shape(song)[0]): \n",
        "            for j in np.arange(78):\n",
        "                if song[i][j] > 0:\n",
        "                    chroma[i][np.mod(j,12)] += 1\n",
        "        #print(np.shape(chroma))\n",
        "        chromas.append(chroma)\n",
        "                \n",
        "    return chromas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ScsP7OZChZYd"
      },
      "outputs": [],
      "source": [
        "# !unzip Pop_Music_Midi.zip;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8iihxLXwEj1w"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gamin\\anaconda3\\envs\\chordgan\\lib\\site-packages\\pretty_midi\\pretty_midi.py:97: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 songs processed\n",
            "10 songs processed\n"
          ]
        }
      ],
      "source": [
        "songs = get_songs('../data/chordGan/Pop/Pop_Music_Midi')[:10]\n",
        "chromas = get_chromas(songs)\n",
        "print (\"{} songs processed\".format(len(songs)))\n",
        "print (\"{} songs processed\".format(len(chromas)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIhhTSj6GtvT"
      },
      "source": [
        "# 2. Setting Up GAN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIaKKrWmEj1w",
        "outputId": "5bd4c581-204f-4706-a2a6-c9edfde2e467"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "624 48\n"
          ]
        }
      ],
      "source": [
        "lowest_note = 0 #the index of the lowest note on the piano roll\n",
        "highest_note = 78 #the index of the highest note on the piano roll\n",
        "note_range = highest_note-lowest_note #the note range\n",
        "\n",
        "num_timesteps  = 4 #This is the number of timesteps that we will create at a time\n",
        "X_dim = 2*note_range*num_timesteps #This is the size of the visible layer. \n",
        "Z_dim = 12*num_timesteps\n",
        "n_hidden = 50 #This is the size of the hidden layer\n",
        "\n",
        "print(X_dim,Z_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uDpINNjpEj1x"
      },
      "outputs": [],
      "source": [
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
        "    return tf.random_normal(shape=size, stddev=xavier_stddev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "24NXtz5IEj1x"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'tensorflow' has no attribute 'placeholder'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20208/1928990959.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#setting up model, discriminator weights and biases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_dim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mD_W1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxavier_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_dim\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mZ_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
          ]
        }
      ],
      "source": [
        "#setting up model, discriminator weights and biases\n",
        "X = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
        "\n",
        "\n",
        "D_W1 = tf.Variable(xavier_init([X_dim+Z_dim, 512]))\n",
        "D_b1 = tf.Variable(tf.zeros(shape=[512]))\n",
        "\n",
        "D_W2 = tf.Variable(xavier_init([512, 1]))\n",
        "D_b2 = tf.Variable(tf.zeros(shape=[1]))\n",
        "\n",
        "theta_D = [D_W1, D_W2, D_b1, D_b2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LRLHyW-CEj1x"
      },
      "outputs": [],
      "source": [
        "#setting up model, generator weights and biases\n",
        "\n",
        "#z is the space we're generating from\n",
        "Z = tf.placeholder(tf.float32, shape=[None, Z_dim])\n",
        "\n",
        "G_W1 = tf.Variable(xavier_init([Z_dim, 128]))\n",
        "G_b1 = tf.Variable(tf.zeros(shape=[128]))\n",
        "\n",
        "G_W2 = tf.Variable(xavier_init([128, X_dim]))\n",
        "G_b2 = tf.Variable(tf.zeros(shape=[X_dim]))\n",
        "\n",
        "theta_G = [G_W1, G_W2, G_b1, G_b2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mIjKz4MwEj1x"
      },
      "outputs": [],
      "source": [
        "def generator(z):\n",
        "    G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)\n",
        "    G_log_prob = tf.matmul(G_h1, G_W2) + G_b2\n",
        "    G_prob = tf.nn.sigmoid(G_log_prob)\n",
        "\n",
        "    return G_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bWImNLv-Ej1y"
      },
      "outputs": [],
      "source": [
        "def discriminator(x,c):\n",
        "    D_h1 = tf.nn.relu(tf.matmul(tf.concat([x,c],1), D_W1) + D_b1)\n",
        "    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n",
        "    D_prob = tf.nn.sigmoid(D_logit)\n",
        "\n",
        "    return D_prob, D_logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tI8yFjDWEj1y"
      },
      "outputs": [],
      "source": [
        "def plot(samples):\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "    gs = gridspec.GridSpec(4, 4)\n",
        "    gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "    for i, sample in enumerate(samples):\n",
        "        ax = plt.subplot(gs[i])\n",
        "        plt.axis('off')\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_aspect('equal')\n",
        "\n",
        "        plt.imshow(sample.reshape(78, 30), cmap='Greys_r')\n",
        "\n",
        "\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKNB6f2oEj1y",
        "outputId": "e450e40f-7652-44d3-888e-d38f0faab224"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(?, 48)\n"
          ]
        }
      ],
      "source": [
        "print (np.shape(Z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "P8CrxuCaEj1z"
      },
      "outputs": [],
      "source": [
        "G_sample = generator(Z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eHEwK5BEj10",
        "outputId": "32c718d5-2c4c-4ebc-df17-43a56bd6cf73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "78\n"
          ]
        }
      ],
      "source": [
        "print(note_range)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kjJ7f5I-Ej10"
      },
      "outputs": [],
      "source": [
        "D_real, D_logit_real = discriminator(X,Z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "n8992jJOEj10"
      },
      "outputs": [],
      "source": [
        "D_fake, D_logit_fake = discriminator(G_sample,Z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "tcYoVloPEj10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\gamin\\anaconda3\\envs\\chordgan\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Alternative losses:\n",
        "# -------------------\n",
        "D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real)))\n",
        "D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))\n",
        "D_loss = D_loss_real + D_loss_fake\n",
        "G_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.ones_like(D_logit_fake)))\n",
        "G_loss_L1 = tf.reduce_mean(tf.losses.mean_squared_error(X,G_sample))\n",
        "G_loss = G_loss_fake + 100*G_loss_L1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Oc9zTKiEEj11"
      },
      "outputs": [],
      "source": [
        "#optimizing functions\n",
        "D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)\n",
        "G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "V_yjcm__Ej11"
      },
      "outputs": [],
      "source": [
        "#output midi file folder\n",
        "if not os.path.exists('out/'):\n",
        "    os.makedirs('out/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wMfONb8gEj11"
      },
      "outputs": [],
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "b''"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sess.sess_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function tensorflow.python.keras.utils.vis_utils.plot_model(model, to_file='model.png', show_shapes=False, show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96)>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.keras.utils.plot_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5f8GfILEj11"
      },
      "outputs": [],
      "source": [
        "# old comment:\n",
        "#         for song in songs:\n",
        "#         # The songs are stored in a time x notes format. The size of each song is timesteps_in_song x 2*note_range\n",
        "#         # Here we reshape the songs so that each training example is a vector with num_timesteps x 2*note_range elements\n",
        "#         song = np.array(song)\n",
        "#         song = song[:np.floor(song.shape[0]/num_timesteps).astype(int)*num_timesteps]\n",
        "#         song = np.reshape(song, [int(song.shape[0]/num_timesteps), song.shape[1]*num_timesteps])\n",
        "#         # Train the RBM on batch_size examples at a time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI2HBr6YGzkM"
      },
      "source": [
        "# 3. Training GAN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "FZBAHllDEj11",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(256, 156)\n",
            "(256, 12)\n",
            "(256, 156)\n",
            "(256, 12)\n"
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "# num_epochs = 200_000\n",
        "num_epochs = 1\n",
        "batch_size = 10\n",
        "#commented out print statements output different losses, and plotting functions plot the piano roll and chroma.\n",
        "# with sess.graph.device(\"GPU\") as g:\n",
        "while i <= num_epochs:\n",
        "    for song, chroma in zip(songs, chromas):      \n",
        "        # The songs are stored in a time x notes format. The size of each song is timesteps_in_song x 2*note_range\n",
        "        # Here we reshape the songs so that each training example is a vector with num_timesteps x 2*note_range elements    \n",
        "        song = np.array(song)     \n",
        "        print(np.shape(song))  \n",
        "        song_steps = np.floor(song.shape[0]/num_timesteps).astype(int)\n",
        "        song = song[:song_steps*num_timesteps]\n",
        "        song = np.reshape(song, [song_steps, song.shape[1]*num_timesteps])  \n",
        "        chroma = np.array(chroma)\n",
        "        print(np.shape(chroma))\n",
        "        chroma = chroma[:song_steps*num_timesteps]\n",
        "        chroma = np.reshape(chroma, [song_steps, chroma.shape[1]*num_timesteps])                \n",
        "        batch_size = min(batch_size,len(song))\n",
        "        # Train the RBM on batch_size examples at a time\n",
        "        break\n",
        "#         for ind in range(0, len(song), batch_size):       \n",
        "#             X_mb = song[ind:ind+batch_size]\n",
        "#             ch = chroma[ind:ind+batch_size]\n",
        "# #            _, loss = sess.run([solver, vae_loss], feed_dict={X: X_mb})\n",
        "#             _, D_loss_curr = sess.run([D_solver, D_loss], feed_dict={X: X_mb, Z: ch})\n",
        "#             _, G_loss_curr = sess.run([G_solver, G_loss], feed_dict={X: X_mb, Z: ch})\n",
        "    \n",
        "#             if i % 1000 == 0:\n",
        "#                 # print('Iter: {}'.format(i))\n",
        "#                 dloss = ('D_Loss: {:.4}'. format(D_loss_curr))\n",
        "#                 gloss = ('G_Loss: {:.4}'. format(G_loss_curr))\n",
        "#                 #print(dloss)\n",
        "#                 #print(gloss)\n",
        "                \n",
        "# #             samples = sess.run(X_samples, feed_dict={z: np.random.randn(1,z_dim)})\n",
        "\n",
        "#                 samples = sess.run(G_sample, feed_dict={Z: ch}) #or here? lol i think it's here actually\n",
        "# #                 print(np.shape(samples), np.shape(ch))\n",
        "        \n",
        "#                 S = np.reshape(samples, (ch.shape[0]*num_timesteps, 2*note_range))\n",
        "#                 thresh_S = S>=0.5\n",
        "\n",
        "#                 thresh_S = np.transpose(thresh_S)\n",
        "\n",
        "\n",
        "#                 C = np.reshape(ch, (ch.shape[0]*num_timesteps, 12))\n",
        "\n",
        "#                 test = reverse_pianoroll.piano_roll_to_pretty_midi(convert.back(thresh_S), fs=16)\n",
        "#                 test.write('out/{}.mid'.format(i))\n",
        "\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9svDngpHzty"
      },
      "source": [
        "# 4. Style Transfer with New Genre Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSzNXQleEj13"
      },
      "outputs": [],
      "source": [
        "#for testing, i'll be using a different dataset of MIDI files to input into the generator here.\n",
        "test_song = get_songs(\"Classical_Music_Midi\")\n",
        "test_chromaz = get_chromas(test_song)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-lb4wigiXTm"
      },
      "outputs": [],
      "source": [
        "#converted midi file folder\n",
        "if not os.path.exists('converted/'):\n",
        "    os.makedirs('converted/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1yURaYKEj14"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "i = 0\n",
        "\n",
        "for c in test_chromaz:\n",
        "    test_chroma = np.array(c)\n",
        "    \n",
        "\n",
        "    test_chroma = test_chroma[:np.floor(test_chroma.shape[0]/num_timesteps).astype(int)*num_timesteps]\n",
        "    test_chroma = np.reshape(test_chroma, [int(test_chroma.shape[0]/num_timesteps), test_chroma.shape[1]*num_timesteps])\n",
        "    #chroma = np.reshape(chroma, [song_steps, chroma.shape[1]*num_timesteps])\n",
        "       \n",
        "    out_samples = sess.run(G_sample, feed_dict={Z: test_chroma})\n",
        "    #print(np.shape(test_chroma),np.shape(samples))\n",
        "    \n",
        "    #print(np.floor(samples.shape[0]*samples.shape[1]/2/note_range).astype(int))\n",
        "    \n",
        "    S = np.reshape(out_samples, (np.floor(out_samples.shape[0]*out_samples.shape[1]/2/note_range).astype(int), 2*note_range))\n",
        "    C = np.reshape(test_chroma, (test_chroma.shape[0]*num_timesteps, 12))\n",
        "    #print(np.shape(S), np.shape(C))\n",
        "    thresh_S = S>=0.5\n",
        "    thresh_S = np.transpose(thresh_S)\n",
        "\n",
        "\n",
        "    \n",
        "    # plt.figure(figsize=(30,18))\n",
        "    # plt.subplot(1,2,1)\n",
        "    # plt.imshow(S)\n",
        "    # plt.subplot(1,2,2)\n",
        "    # plt.imshow(C)\n",
        "    # #plt.tight_layout()\n",
        "    # plt.pause(0.1)\n",
        "\n",
        "\n",
        "    test = reverse_pianoroll.piano_roll_to_pretty_midi(convert.back(thresh_S), fs=16)\n",
        "    test.write('converted/{}.mid'.format(i))\n",
        "\n",
        "    # midi_manipulation.noteStateMatrixToMidi(thresh_S, \"new/generated_chord_{}\".format(i))\n",
        "    # i+=1\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "GANMIDItest.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
